# 自旋锁
![image](https://raw.githubusercontent.com/lewiszlw/notebooks/master/assets/cs-basic-knowledge/%E8%87%AA%E6%97%8B%E9%94%81%E5%92%8C%E9%9D%9E%E8%87%AA%E6%97%8B%E9%94%81%E5%8A%A0%E9%94%81%E6%B5%81%E7%A8%8B.png)

自旋锁（spin lock）是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。（[自旋锁Java实现](https://github.com/lewiszlw/hello-world/tree/master/hello-world-java/src/main/java/lewiszlw/lock/spinlock)）

自旋锁问题
1. 如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。
2. 上面Java实现的自旋锁不是公平的，即无法满足等待时间最长的线程优先获取锁。不公平的锁就会存在“线程饥饿”问题。
3. 死锁问题：递归程序决不能在持有自旋锁时调用它自己，也决不能在递归调用时试图获得相同的自旋锁。

自旋锁优点
1. 自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快
2. 非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）

**适应性自旋锁**
自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。

# 公平锁和非公平锁
- 公平锁：指线程在等待获取同一个锁的时候，是严格按照申请锁的时间顺序来进行的
- 非公平锁：随机线程获取锁，效率相对高

# 可重入锁和不可重入锁
- 可重入锁：当一个线程获取了A锁以后，若后续方法运行被A锁锁住的话，当前线程也是可以直接进入的
- 不可重入锁：当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞

# 死锁产生条件
1. 互斥条件：一个资源每次只能被一个进程使用。 
2. 请求与保持条件（部分分配）：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 
3. 不可剥夺条件：进程已获得的资源，在使用完之前，不能强行剥夺。
4. 循环等待条件（环路）：若干进程之间形成一种头尾相接的循环等待资源关系。

**解决死锁**
1.加锁时限
2.申请资源时一次性申请所需要的全部资源
3.避免嵌套封锁

# 进程调度算法
**先来先服务调度算法（FCFS）**

选择一个或多个最先进入该队列的作业进行调度。

**短作业(进程)优先调度算法**

从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。

**高优先权优先调度算法**

1. 非抢占式优先权调度算法：系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成或主动让出
2. 抢占式优先权调度算法：在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程

**时间片轮转法**

系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几ms 到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。

**多级反馈队列调度算法**

调度过程：
1. 设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小；
2. 当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第n队列后，在第n 队列便采取按时间片轮转的方式运行。
3. 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i队列的末尾，把处理机分配给新到的高优先权进程。

# 进程间通信方式
**管道（pipe）、流管道（s_pipe）和有名管道（FIFO）**

匿名管道/管道（pipe）：是半双工的通信，数据只能单向流动，二是只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

流管道可以双向传输。

高级管道(popen)：将另一个程序当做一个新的进程在当前程序进程中启动，则它算是当前程序的子进程，这种方式我们成为高级管道方式。

有名管道(named pipe)：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

管道的实质：

管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。该缓冲区可以看做是一个循环队列，读和写的位置都是自动增长的，不能随意改变，一个数据只能被读一次，读出来以后在缓冲区就不复存在了。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或者写进程进入等待队列，当空的缓冲区有新数据写入或者满的缓冲区有数据读出来时，就唤醒等待队列中的进程继续读写。

**信号（signal）**

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

**消息队列**

消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

**共享内存**

共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。

**信号量（semophore）**

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

**套接字（socket)**

套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。

# 进程和线程
- 地址空间和其他资源：进程间相互独立，同一进程的各线程间共享。
- 通信：进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信－－需要线程同步和互斥手段的辅助，以保证数据的一致性。
- 调度：线程上下文切换比进程上下文切换要快得多。进程调度和切换都是由操作系统内核来完成，而线程既可由操作系统内核来完成也可由用户程序来完成。
- 状态：线程和进程一样，都有自己的状态．也有相应的同步机制，不过，由于线程没有单独的数据和程序空间，因此，线程不能像进程的数据与程序那样，交换到外存存储空间

# UNIX 五种IO模型
**1.阻塞 IO 模型**

![image](https://raw.githubusercontent.com/lewiszlw/notebooks/master/assets/linux/Unix%E9%98%BB%E5%A1%9E%E5%BC%8FIO%E6%A8%A1%E5%9E%8B.jpeg)

典型的阻塞 IO 模型的例子为:data = socket.read();如果数据没有就绪，就会一直阻塞在 read 方法。

**2.非阻塞 IO 模型**

![image](https://raw.githubusercontent.com/lewiszlw/notebooks/master/assets/linux/Unix%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%BC%8FIO%E6%A8%A1%E5%9E%8B.jpeg)

当用户线程发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果。如果结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。

用户线程需要不断地询问内核数据是否就绪，也就说非阻塞 IO 不会交出 CPU，而会一直占用 CPU。

**3.多路复用 IO 模型**

![image](https://raw.githubusercontent.com/lewiszlw/notebooks/master/assets/linux/Unix%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8IO%E6%A8%A1%E5%9E%8B.jpeg)

有一个线程不断去轮询多个 socket 的状态，只有当 socket 真正有读写事件时，才真正调用实际的 IO 读写操作。

另外多路复用 IO 为何比非阻塞 IO 模型的效率高是因为在非阻塞 IO 中，不断地询问 socket 状态
时通过用户线程去进行的，而在多路复用 IO 中，轮询每个 socket 状态是内核在进行的，这个效率要比用户线程要高的多。

**4.信号驱动 IO 模型**

![image](https://raw.githubusercontent.com/lewiszlw/notebooks/master/assets/linux/Unix%E4%BF%A1%E5%8F%B7%E9%A9%B1%E5%8A%A8IO%E6%A8%A1%E5%9E%8B.jpeg)

在信号驱动 IO 模型中，当用户线程发起一个 IO 请求操作，会给对应的 socket 注册一个信号函 数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到 信号之后，便在信号函数中调用 IO 读写操作来进行实际的 IO 请求操作。

**5.异步 IO 模型**

![image](https://raw.githubusercontent.com/lewiszlw/notebooks/master/assets/linux/Unix%E5%BC%82%E6%AD%A5IO%E6%A8%A1%E5%9E%8B.jpeg)

异步 IO 模型才是最理想的 IO 模型，在异步 IO 模型中，当用户线程发起 read 操作之后，立刻就 可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个 asynchronous read 之后， 它会立刻返回，说明 read 请求已经成功发起了，因此不会对用户线程产生任何 block。然后，内 核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程 发送一个信号，告诉它 read 操作完成了。也就说用户线程完全不需要实际的整个 IO 操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示 IO 操作已经完成，可以直接 去使用数据了。